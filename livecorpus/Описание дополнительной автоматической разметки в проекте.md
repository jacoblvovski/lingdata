В качестве дополнительной автоматической разметки в проекте я решил сделать упрощённую семантическую разметку. Идея заключалась в том, чтобы разметить три самых близких (согласно векторным моделям) синонима к каждому слову каждой ЭДЕ. С практической точки зрения это может быть полезно при поиске фрагментов видео по темам. Для этого поисковик корпуса можно немного доработать - составить список слов, относящихся к теме (например, названия различных овощей для темы "овощи"), дав пользователю возможность запускать поисковик по словам этой темы (дав алгоритму задачу искать все фрагменты, в которых встречается хотя бы одно слово из списка). Если искать не только по самой расшифровке, но и по дополнительной разметке, можно быстрее отбирать круг подходящих к теме примеров. <br/><br/>
Чтобы реализовать подобную разметку в рамках проекта, я применил модель ruscvectores через скрипт на python (в этой папке репозитория он лежит под названием [semantic annotation.py](https://github.com/jacoblvovski/lingdata/blob/main/livecorpus/semantic%20annotation.py)). Перед подачей в модель слова предобрабатывались (проводилась лемматизация и слову приписывался его частеречный тег, чтобы снизить число случаев неправильной интепретации из-за морфологической омонимии) с помощью алгоритма синтагрус. Разбиение ЭДЕ на токены проводилось с помощью модуля nltk. В разметку записывались три ближайших синонима к каждому слову, которое было известно модели (это в основном существительные, прилагательные, глаголы и качественные наречия).<br/><br/>
Разумеется, такая разметка является довольно приблизительной и для серьёзной работы следует искать более продвинутые решения (использовать алгоритмы тематического моделирования на более широких кусках расшифровки, обучать векторные модели на корпусе текстов расшифровок и многие другие). Проблемы с этим решением возникли в основном в том, что особенности контекста могут приводить к некорректному или неточному поиску. Например: в фрагменте обсуждается спортивное "Что? Где? Когда?", часто фигурирует слово "тренер", а среди ближайших его синонимов модель находит слово "хоккеист". При широком поиске по теме "спорт" это ещё может подойти (тут скорее вопрос к тому, насколько ищущему интересны тексты о спортивном "Что? Где? Когда?"), но при более специальных темах, хотя бы теме "Хоккей" алгоритм будет выдавать некорректные результаты. Иногда возникают проблемы и из-за морфологической омонимии. Самый яркий пример - слово "блин", которое информантка использует в качестве междометия, но модель этого уловить не может, а поэтому в качестве синонимов выдаёт слова, связанные с едой. Впрочем надеюсь, что семантическая разметка с помощью векторных моделей (сделанная более продуманно, чем представленный здесь вариант) как область развития имеет потенциал. <br/><br/>
Часть кода была взята из [материала "Системного Блока"](https://sysblok.ru/knowhow/obuchaem-word2vec-praktikum-po-sozdaniju-vektornyh-modelej-jazyka/). Код, использовавшийся для подготовки таблицы на импорт находится в файле [forming table_2.py](https://github.com/jacoblvovski/lingdata/blob/main/livecorpus/forming%20table_2.py), cами данные для импорта в файле [sem_annotated_elan_data.tsv](https://github.com/jacoblvovski/lingdata/blob/main/livecorpus/sem_annotated_elan_data.tsv).
